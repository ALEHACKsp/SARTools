%\VignetteIndexEntry{SARTools tutorial}
%\VignettePackage{SARTools}
%\VignetteEngine{knitr::knitr}

\documentclass[12pt]{article}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{amsmath}

<<knitr, echo=FALSE, results="hide">>=
library("knitr")
opts_chunk$set(tidy=FALSE,dev="png",fig.show="hide",
               fig.width=4,fig.height=4.5,
               message=FALSE)
@ 

<<style-knitr, eval=TRUE, echo=FALSE, results="asis">>=
BiocStyle::latex()
@

\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}
\lstset{
  backgroundcolor=\color{white},   % choose the background color; you must add \usepackage{color} or \usepackage{xcolor}
  basicstyle=\scriptsize\ttfamily, % the size of the fonts that are used for the code
  breakatwhitespace=false,         % sets if automatic breaks should only happen at whitespace
  breaklines=true,                 % sets automatic line breaking
  captionpos=b,                    % sets the caption-position to bottom
  columns=flexible,
  commentstyle=\color{mygreen},    % comment style
  extendedchars=false,             % lets you use non-ASCII characters; for 8-bits encodings only, does not work with UTF-8
  fontadjust=true,
  frame=trBL,                      % adds a frame around the code
  keepspaces=true,                 % keeps spaces in text, useful for keeping indentation of code (possibly needs columns=flexible)
  keywordstyle=\color{blue},       % keyword style
  language=R,                      % the language of the code
  numbers=none,                    % where to put the line-numbers; possible values are (none, left, right)
  numbersep=5pt,                   % how far the line-numbers are from the code
  numberstyle=\tiny\color{mygray}, % the style that is used for the line-numbers
  rulecolor=\color{black},         % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. comments (green here))
  showspaces=false,                % show spaces everywhere adding particular underscores; it overrides 'showstringspaces'
  showstringspaces=false,          % underline spaces within strings only
  showtabs=false,                  % show tabs within strings adding particular underscores
  stepnumber=2,                    % the step between two line-numbers. If it's 1, each line will be numbered
  stringstyle=\color{mymauve},     % string literal style
  tabsize=2,                       % sets default tabsize to 2 spaces
  title=\lstname                   % show the filename of files included with \lstinputlisting; also try caption instead of title
}

\newcommand{\deseq}{\Biocpkg{DESeq2}}
\newcommand{\edger}{\Biocpkg{edgeR}}

\bioctitle[\Rpackage{SARTools} vignette]{\Rpackage{SARTools} vignette for the differential analysis of 2 or more conditions with \deseq~or \edger}
\author{M.-A. Dillies and H. Varet$^{*}$ \\ \small{Transcriptome and Epigenome Platform, Institut Pasteur, Paris} \\ \small{$^*$ \email{hugo.varet@pasteur.fr}}}

\begin{document}
\maketitle
\tableofcontents

\section{Introduction}

This document aims to illustrate the use of the \Rpackage{SARTools} \R{} package in order to compare two or more biological conditions in a RNA-Seq framework. \Rpackage{SARTools} provides tools to generate descriptive and diagnostic graphs, to run the differential analysis with one of the well known \deseq~\cite{anders2010,love2014} or \edger~\cite{robinson2009} packages and to export the results into easily readable tab-delimited files. It also facilitates the generation of a HTML report which displays all the figures produced, explains the statistical methods and gives the results of the differential analysis. Note that \Rpackage{SARTools} does not intend to replace \deseq~or \edger: it simply provides an environment to go with them. For more details about the methodology behind \deseq~and \edger, the user should read their documentations and papers. \\

\Rpackage{SARTools} is distributed with two \R{} script templates which use functions of the package. For a more fluid analysis and to avoid possible bugs when creating the final HTML report, the user is encouraged to use them rather than writing a new script. \\

The next section details the tools and files required to perform an analysis and the third section explains the different steps of the analysis. Section 4 gives some examples of problems which can occur during an analysis and section 5 provides command lines to run a toy example of the workflow. Complete \R{} scripts of the workflow are given in the appendix.

\section{Prerequisites}
\subsection{\R{} tools}

In addition to the \Rpackage{SARTools} package itself, the workflow requires the installation of several packages: \deseq, \edger, \Biocpkg{genefilter}, \CRANpkg{xtable} and \CRANpkg{knitr} (all available online). This current version of \Rpackage{SARTools} has been developed under \R{}~3.1.1 and with \deseq~1.6.1, \edger~3.8.2, \Biocpkg{genefilter}~1.48.1 and \CRANpkg{knitr}~1.7. As a \deseq~or \edger~update might make the workflow unusable due to modifications on the statistical models, care is recommended when updating these packages. \\

The only file the user has to deal with for an analysis is either \file{template\_script\_DESeq2.r} or \file{template\_script\_edgeR.r} (supplied in the appendix at the end of this vignette). They contain all the code needed for the statistical analysis, and to generate figures, tables and the HTML report.

\subsection{Data files}

The statistical analysis assumes that reads have already been mapped and that counts per feature (gene or transcript) are available. If counting has been done with \texttt{HTSeq-count} \cite{htseq,anders2014}, output files are ready to be loaded in \R{} with the dedicated \Rpackage{SARTools} function. If not, the user must supply one count file per sample with two tab delimited columns without header:
\begin{itemize}
	\item the unique IDs of the features in the first column;
	\item the raw counts associated with these features in the second column (null or positive integers).
\end{itemize}

All the count data files have to be placed in a directory whose name will be passed as a parameter at the beginning of the \R{} script. \\

The user has to supply another tab delimited file which describes the experiment, i.e. which contains the name of the biological condition associated with each sample. This file is called "target" as a reference to the target file needed when using the \Biocpkg{limma} package \cite{limma}. This file has one row per sample and is composed of at least three columns with headers: 
\begin{itemize}
	\item first column: unique names of the samples (short but informative as they will be displayed on all the figures);
	\item second column: name of the count files;
	\item third column: biological conditions;
	\item optional columns: further information about the samples (day of library preparation for example).
\end{itemize}

The table \ref{extarget} below shows an example of a target file:
\begin{table}[h!]
\centering
\texttt{
\begin{tabular}{lll}
label & files & group \\
s1c1 & count\_file\_sample1\_cond1.txt & cond1 \\
s2c1 & count\_file\_sample2\_cond1.txt & cond1 \\
s1c2 & count\_file\_sample1\_cond2.txt & cond2 \\
s2c2 & count\_file\_sample2\_cond2.txt & cond2 \\
\end{tabular}
}
\caption{Example of target file}
\label{extarget}
\end{table}

\warning{if the counts and the target files are not supplied in the required formats, the workflow will probably crash and will not be able to run the analysis.}

\section{Running the analysis}

\subsection{Setting the parameters}

All the parameters that can be modified by the user are at the beginning of the \R{} template files:

\begin{itemize}
	\item \Rcode{workDir}: path to the working directory for the \R{} session (must be supplied by the user);
	\item \Rcode{projectName}: name of the project (must be supplied by the user);
	\item \Rcode{author}: author of the analysis (must be supplied by the user);
	\item \Rcode{targetFile}: path to the target file (\Rcode{"target.txt"} by default);
	\item \Rcode{rawDir}: path to the directory where the counts files are stored (\Rcode{"raw"} by default);
	\item \Rcode{featuresToRemove}: character vector containing the IDs of the features to remove before running the analysis (default are \Rcode{"alignment\_not\_unique"}, \Rcode{"ambiguous"}, \Rcode{"no\_feature"}, \Rcode{"not\_aligned"}, \Rcode{"too\_low\_aQual"} to remove \texttt{HTSeq-count} specific rows);
	\item \Rcode{varInt}: variable of interest, i.e. biological condition, in the target file (\Rcode{"group"} by default);
	\item \Rcode{condRef}: reference biological condition used to compute fold-changes (no default, must be one of the levels of \Rcode{varInt});
	\item \Rcode{batch}: adjustment variable to use as a batch effect, must be a column of the target file (\Rcode{NULL} if no batch effect needs to be taken into account);
	\item \Rcode{fitType}: (if use of \deseq) type of model for the mean-dispersion relationship (\Rcode{"parametric"} by default, or \Rcode{"local"});
	\item \Rcode{cooksCutoff}: (if use of \deseq) \Rcode{NULL} to let \deseq~choosing the threshold for the outlier detection, \Rcode{Inf} to turn off the outlier detection or a numeric of length one to give a specific value \cite{Cook1977Detection};
	\item \Rcode{independentFiltering}: (if use of \deseq) \Rcode{TRUE} (default) of \Rcode{FALSE} to execute or not the independent filtering \cite{bourgon2010};
	\item \Rcode{alpha}: significance threshold applied to the adjusted p-values to select the differentially expressed features (default is \Rcode{0.05});
	\item \Rcode{pAdjustMethod}: p-value adjustment method for multiple testing \cite{bh1995,yekutieli} (\Rcode{"BH"} by default, \Rcode{"BY"} or any value of \Rcode{p.adjust.methods});
	\item \Rcode{typeTrans}: (if use of \deseq) method of transformation of the counts for the clustering and the PCA (default is \Rcode{"VST"} for Variance Stabilizing Transformation, or \Rcode{"rlog"} for Regularized Log Transformation);
	\item \Rcode{locfunc}: (if use of \deseq) function used for the estimation of the size factors (default is \Rcode{"median"}, or \Rcode{"shorth"} from the \Biocpkg{genefilter} package);
	\item \Rcode{cpmCutoff}: (if use of \edger) counts-per-million cut-off to filter low counts (default is 1, set to 0 to disable filtering);
	\item \Rcode{gene.selection}: (if use of \edger) method of selection of the features for the MultiDimensional Scaling plot (\Rcode{"pairwise"} by default or \Rcode{common});
	\item \Rcode{colors}: colors used for the figures (one per biological condition), 4 are given by default.
\end{itemize}

All these parameters will be saved and written at the end of the HTML report in order to keep track of what has been done.

\subsection{Executing the script}

When the parameters have been defined, the user can run all the \R{} code, either step by step or in one block. The command lines use functions of the \Rpackage{SARTools} package to load data, to produce figures, to perform the differential analysis, to export the results and to create the HTML report. Some results and potential warning/error messages will be printed in the \R{} console:
\begin{itemize}
	\item target with the count files loaded and the biological condition associated with each sample;
	\item number of features and null counts in each file;
	\item top and bottom of the count matrix;
	\item SERE coefficients computed between each pair of samples \cite{sere};
	\item normalization factors (TMM for \edger~and size factors for \deseq);
	\item number of features discarded by the independent filtering (if use of \deseq);
	\item number of differentially expressed features.
\end{itemize}

If the \R{} code was executed in one block, the user should have a look at the console at the end of the analysis to check that the analysis ran without any problem.

\subsection{Files generated}

While running the script, PNG files are generated in the \texttt{figures} directory:
\begin{itemize}
	\item \file{barplotTC.png}: total number of reads per sample;
	\item \file{barplotNull.png}: percentage of null counts per sample;
	\item \file{densplot.png}: estimation of the density of the counts for each sample;	
	\item \file{majSeq.png}: percentage of reads caught by the feature having the highest count in each sample;
	\item \file{pairwiseScatter.png}: pairwise scatter plot between each pair of samples and SERE values;
	\item \file{diagSizeFactorsHist.png}: diagnostic of the estimation of the size factors (if use of \deseq);
	\item \file{diagSizeFactorsTC.png}: plot of the size factors vs the total number of reads (if use of \deseq);
	\item \file{countsBoxplot.png}: boxplots on raw and normalized counts;	
	\item \file{cluster.png}: hierachical clustering of the samples (based on VST or rlog data for \deseq, or CPM data for \edger);
	\item \file{PCA.png}: first and second factorial planes of the PCA on the samples based on VST or rlog data (if use of \deseq);
	\item \file{MDS.png}: Multi Dimensional Scaling plot of the samples (if use of \edger);
	\item \file{dispersionsPlot.png}: graph of the estimations of the dispersions and diagnostic of log-linearity of the dispersions (if use of \deseq);
	\item \file{BCV.png}: graph of the estimations of the tagwise, trended and common dispersions (if use of \edger);
	\item \file{rawpHist.png}: histogram of the raw p-values for each comparison;
	\item \file{MAplot.png}: MA-plot for each comparison (log ratio of the means vs intensity).
\end{itemize}

Some tab-delimited files are exported in the \texttt{tables} directory. They store information on the features as $\log_2\text{(FC)}$ or p-values and can be read easily in a spreadsheet:
\begin{itemize}
	\item \file{TestVsRef.complete.txt}: contains all the features studied;
	\item \file{TestVsRef.down.txt}: contains only significant down-regulated features, i.e. less expressed in Test than in Ref;
	\item \file{TestVsRef.up.txt}: contains only significant up-regulated features i.e. more expressed in Test than in Ref.
\end{itemize}

A \file{.RData} file with all the \R{} objects created during the analysis is saved: it may be used to perform downstream analyses. Finally, a HTML report which explains the full analysis is produced. Its goal is to give details about the methodology, the different steps and the results. It displays all the figures produced and the most important results of the differential analysis as the number of up- and down-regulated features. The user should read the full HTML report and closely analyze each figure to check that the analysis ran smoothly. \\

Note that the HTML report is stand alone and can be shared without the source figure files. It makes the report easily sendable via e-mail for instance.

\section{Troubleshooting RNA-seq experiments with \Rpackage{SARTools}}

This section aims at listing some problems that the user can face when analyzing data from a RNA-Seq experiment.

\subsection{Inversion of samples}
For a variety of reasons, it might happen that some sample names are erroneously switched at a step of the experiment. This can be detected during the statistical analysis in several ways. Here, we have intentionally inverted two file names in a target file, such that the counts associated with these two samples (WT3 and KO3) are inverted. \\

The first tool to detect the inversion is the SERE statistic \cite{sere} since its goal is to measure the similarity between samples. The SERE values obtained are displayed on the lower triangle of the figure \ref{inversionSERE}. We clearly observe that KO3 is more similar to WT1 (SERE$=1.7$) than to KO2 ($3.4$), which potentially reveals a problem within the samples under study. The same phenomenon happens with WT3 which is more similar to KO1 ($1.6$) than to WT1 ($4.59$).\\

\begin{figure}[h!]
\centering
\includegraphics[width=0.45\textwidth]{inversionpairwiseScatter.png}
\caption{Pairwise scatter plot and SERE statistics when inverting samples}
\label{inversionSERE}
\end{figure}

The clustering can also help detect such an inversion of samples. Indeed, on the dendrogram, samples from the same biological condition are supposed to cluster together while samples from two different biological conditions should group only at the final step of the algorithm. Figure \ref{inversionClusterPCA} (left) shows the dendrogram obtained: we can see that KO3 clusters immediately with WT1 and WT2 while WT3 clusters with KO1 and KO2. \\

The Principal Component Analysis on the right panel of figure \ref{inversionClusterPCA} (or the Multi-Dimensional Scaling plot) is a tool which allows exploration of the structure of the data. Samples are displayed on a two dimensional graph which can help the user to assess the distances between samples. The PCA presented here leads to the same conclusion as the dendrogram. \\

\begin{figure}[h!]
\centering
\includegraphics[width=0.40\textwidth]{inversioncluster.png}
\includegraphics[width=0.40\textwidth]{inversionPCA.png}
\caption{Clustering dendrogram (left) and PCA (right) when inverting samples}
\label{inversionClusterPCA}
\end{figure}

Finally, when testing for differential expression, if two samples have been inverted during the process, the histogram of the raw p-values can have an unexpected shape. Instead of having a uniform distribution, with a possible peak at $0$ for the differentially expressed features, the distribution may be skewed toward the right (figure \ref{inversionHist}).

\begin{figure}[h!]
\centering
\includegraphics[width=0.4\textwidth]{inversionrawpHist.png}
\caption{Raw p-values histogram when inverting samples}
\label{inversionHist}
\end{figure}

\subsection{Batch effect}
A batch effect is a source of variation in the counts due to splitting the whole sample set into subgroups during the wet-lab part of the experiment. To illustrate this phenomenon, figure \ref{batchclusterPCA} shows the results of the clustering and of the PCA for an experiment with 12 samples: 6 WT and 6 KO labeled from 1 to 6 within each condition. \\

\begin{figure}[h!]
\centering
\includegraphics[width=0.40\textwidth]{batchcluster.png}
\includegraphics[width=0.40\textwidth]{batchPCA.png}
\caption{Clustering dendrogram (left) and PCA (right) with a batch effect}
\label{batchclusterPCA}
\end{figure}

The first axis of the PCA, which catches 64.36\% of the variability, clearly separates WT samples from KO samples. However, we can see that the second axis separates samples labeled 1, 2 and 3 from samples labeled 4, 5 and 6 with a large percentage of variability (20.97\%). The clustering brings to the same conclusion: samples 1, 2 and 3 seem slightly different from samples 4, 5 and 6, both within WT and KO. \\

After a return to the conditions under which the experiment has been conducted, it has been found that the first three samples were not prepared on the same day as the last three ones (both for WT and KO). This is enough to create a batch effect. In that case, add a column to the target file reporting the day of preparation, set the \Rcode{batch} parameter value to "day of preparation" and re-do the analysis. It will result in a better fit of the model and potentially a gain of power when testing for differentially expressed features.\\


\warning{batch effects can be taken into account only if they do not confound with another technical or biological factor included in the model.}

%In this situation, the analysis must be reran taking the "day of preparation" effect into account by adding it both to the target file (in a new column) and to the design of the model as a blocking factor (\Rcode{batch} parameter at the beginning of the \R{} scripts).

\subsection{Number of reads and outliers}
A sample with a total number of reads or a number of null counts too much different from the others may reveal a problem during the experiment, the sequencing or the alignment. The user can check this in the two first barplots of the HTML report (total number of reads and percentage of null counts). Moreover, such a sample will probably be outlier on the PCA/MDS plot, i.e. it will fall far from the other samples. It will often be preferable to remove it from the statistical analysis. For example, the figures \ref{outlierTCnull} and \ref{outlierPCA} illustrate this phenomenon and suggest the removal of sample WT3 from the analysis.

\begin{figure}[h!]
\centering
\includegraphics[width=0.40\textwidth]{outlierbarplotTotal.png}
\includegraphics[width=0.40\textwidth]{outlierbarplotNull.png}
\caption{WT3 has a small total number of reads (left) and a high percentage of null counts (right)}
\label{outlierTCnull}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=0.40\textwidth]{outlierPCA.png}
\caption{WT3 falls far from the other samples on the first factorial plane of the PCA}
\label{outlierPCA}
\end{figure}

\subsection{Ribosomal RNA}
It may happen that some features (ribosomal RNA for example) take up a large number of reads (up to 20\% or more). The user can detect them in a barplot in the HTML report. If these are not of interest for the experiment, these features can be removed by adding them to the \Rcode{featuresToRemove} argument at the beginning of the \R{} scripts.

\subsection{Normalization parameter (only with \deseq)}
In order to normalize the counts, \deseq~computes size factors. There are two options to compute them: \Rcode{"median"} (default) or \Rcode{"shorth"}. The default parameter often works well but the HTML report contains a figure which allows an assessment of the quality of the estimation of the size factors: there is one histogram per sample with a vertical red line corresponding to the value of the size factor. If the estimation of the size factor is correct, the red line must fall on the mode of the histogram for each sample. If this is not the case, the user should use the \Rcode{"shorth"} parameter. Results with \Rcode{"median"} and \Rcode{"shorth"} for the same sample are given on figure \ref{diagSF} for an experiment where it was preferable to use \Rcode{"shorth"}.

\begin{figure}[h!]
\centering
\includegraphics[width=0.8\textwidth]{diagSF.png}
\caption{Size factor diagnostic for one sample with \Rcode{"median"} (left) and \Rcode{"shorth"} (right)}
\label{diagSF}
\end{figure}


\section{Toy example}
A target file and counts files (4 samples: 2 WT and 2 KO) for a toy example are available within the package to enable the user to test the workflow. The target file and the directory containing the counts files can be reached with the following lines:
\begin{lstlisting}
targetFile <- system.file("target.txt", package="SARTools")
rawDir <- system.file("raw", package="SARTools")
\end{lstlisting}

The user can try the \R{} scripts available in the appendix with the parameters above (all the others remaining unchanged).

\clearpage
\appendix
\section{\R{} script templates}
Below are the \R{} codes of the workflow. The user can copy and paste them in a text editor to modify the parameters and run the analysis with \R{}. The two scripts are also available in the directory where the package has been installed (i.e. the \file{SARTools} directory of the \R{} packages library). Even if it is possible to run all the code directly, it is preferable to run it step by step in order to detect possible warning/error messages when they appear. Note that the code to load data and to generate graphs is similar between the two files. The main difference begins when using the \deseq~or \edger~functions.

\subsection{\file{template\_script\_DESeq2.r}}
\lstinputlisting[caption=]{\Sexpr{system.file("template_script_DESeq2.r",package="SARTools")}}

\clearpage
\subsection{\file{template\_script\_edgeR.r}}
\lstinputlisting[caption=]{\Sexpr{system.file("template_script_edgeR.r",package="SARTools")}}

\clearpage
\bibliography{library}

\end{document}